## Anthropic、自律型AI「Cowork」発表　デスクトップ作業を丸投げ可能に

* https://www.itmedia.co.jp/aiplus/articles/2601/13/news051.html

Claude Codeのプログラマ以外向け版みたいな感じですね。

## AnthropicがClaude Codeを使い1週間半でCoworkを構築

* https://x.com/kubotamas/status/2011146663109542311

そして、驚きなのが、この Cowork全コード Claude Code製。しかも開発期間は１週間半とのこと。
Claude Codeの開発者が作っているので、CluadeCode自体を改良しながら開発していた気がします。
いや、それだとしてもすごいんですけどね。

## AI補助でエルデシュ未解決問題が昨年末から驚異的ペースで解決中

* https://x.com/monoxxxx/status/2011013533656616999

AIの補助で、数学の未解決問題が凄いペースで解決しているとのこと。
ただし、割と難易度が低めなものが解決しているだけで、数学者自体が不要にはならないというツイートも見かけました。

## AIがエルデシュ問題#728を解決、GPT-5.2とAristotleによる証明論文がarXivに掲載

* https://x.com/itnavi2022/status/2010997919269470600

こちらは、AIが単独で解決して、数学者が裏を取った証明だそうです。

## 同一プロンプト２重入力でLLM精度大幅向上、推論機能並みの効果を確認

* https://twitter.com/webbigdata/status/2010610147106914626
* Prompt Repetition Improves Non-Reasoning LLMs
* https://arxiv.org/abs/2512.14982

重要なことを２度言うと、精度が向上するとのこと。
ホントかよ、と言うのが素直な感想なんですが、twitter上では実際にやってみて、Reasoningにするより精度が高くなったとか言っている人もいました。
とりあえず、論文のタイトルが、Prompt Repetition Improves Non-Reasoning LLMs なので、Reasoningモデルは対象外のようです。

## LLMエージェントは長期タスクでコンテキスト肥大化とエラー蓄積により性能劣化する

* https://x.com/omarsar0/status/2009662975024447511
* https://arxiv.org/abs/2601.03204

長期タスクでのコンテキスト肥大化・エラー蓄積の性能劣化を少なくするためのフレームワークのようです。

## Phi-3.5 MiniでGPT-4oと同等精度、コスト1/19・速度17倍実現

* https://x.com/webbigdata/status/2008778269311783298
* https://x.com/webbigdata/status/2008778271392231606
* https://arxiv.org/abs/2601.03211

社内文書検索用にPhi-3.5 Mini (3.8B)をファインチューニングして検索結果を採点するモデルを作成したとのこと。

## NVIDIA、性能5倍向上のAI GPU「Rubin」を2026年後半リリース予定と発表

* https://pc.watch.impress.co.jp/docs/news/event/2075697.html

5倍とか性能向上しすぎだろ！と言うのが素直な感想

## (人工知能学会)大規模言語モデルと知識グラフに関するブックマーク記事

https://www.ai-gakkai.or.jp/resource/my-bookmark/my-bookmark_vol41-no1/

## Gemini 3 Pro、事実は雑だが表現は丁寧という評価

* https://x.com/super_bonochin/status/2007817900753866923


## 7歳娘がVibeコーディングゲームで文章作成、AIの即座フィードバックで国語力向上

* https://x.com/marurur/status/2007481476741509391

これ、すごく面白いです。
娘さん、文章の不備がそのままVibeCodingで作られる成果物に直結するため、すごく真剣にプロンプトの日本語を推敲しているとのこと。
この観点はありませんでした。

## MIT研究：ニューラルネットワーク90%削除でも精度維持

* https://x.com/kosuke_agos/status/2007331973136785455

ちょっと、このツイートには不正確なところがあって、この研究は学習前に乱数で初期化するときのパラメータについての言及になっています。
大規模なパラメータのLLMで学習をして、その後、有効なパラメータだけ10%抽出。
その10%のパラメータの箇所を初期値に戻してあげて、その10%だけで同じ学習を実施すると、大規模で学習した時と同じレベルまで学習できることを発見したようです。
このパラメータのことを当たりくじ、と言っていて、大規模パラメータの方が当たりくじが多いので学習しやすいのでは？という仮説ですね。
何が当たりくじなのかは分かっておらず、今後の課題だとのこと

## Meta、中国AIスタートアップManusを最大30億ドルで買収、ByteDance提案を上回る

* https://x.com/kajikent/status/2007264042692555054

実はManusの創業者らは会社をシンガポールに移転、北京チームを全員レイオフ、Tencentの持分を買い戻し、
中国との所有・運営上のつながりを完全に断ち切った上で、Metaに20~30億ドル(厳密には非公開)で売却したのだとか。

なるほど。中国国内で売却するのの100倍で売れたとのこと
すごい事をしますよね。中国政府に睨まれないんでしょうか　笑

## DGX Sparkとnanochatで丸一日かけてLLMを自作、日本語学習を追記

* https://zenn.dev/karaage0703/articles/aedade69a9463f

からあげさんの記事
nanochatは、LLMの仕組みの勉強に良さそうな気がしています。

## Claude Codeのツール検索機能でMCPツールのトークン使用量を大幅削減

* https://x.com/azukiazusa9/status/2005887536070279249

トークン使用量が 39,000 ⇒ 2,800 に減ったとのこと

## Anthropic公式プロンプトエンジニアリング教材が人気、9章構成で段階的学習可能

* https://github.com/anthropics/prompt-eng-interactive-tutorial

## バックプロパゲーション発明者ヒントンが新学習法Forward-Forwardを提案

* https://x.com/ShimmyoLab/status/2004804498326520140

## AI導入は人員削減より業務効率化で付加価値創出が5倍効果的

* https://twitter.com/ai_database/status/2001124692321812839
* https://arxiv.org/abs/2506.06576

うーん？　参考として挙げられている論文(https://arxiv.org/abs/2506.06576)は以下のような感じだから、別の調査結果があるのかもしれません。

本研究の4つの主要な発見
* 専門労働者は低価値で反復的なタスクの自動化を望んでいる
* 職場におけるAIエージェントの要望-能力の景観を視覚化し、重要なミスマッチを発見
* 労働者は一般的により高いレベルの人間の主体性を好み、AI能力が進歩するにつれて摩擦が生じる可能性を示唆している
* 主要な人間のスキルは情報処理から対人能力へシフトしている

### 職業タスク自動化に関する労働者中心の見解

#### 労働者はどこでAIエージェントによる自動化を望んでいるか？

職業タスクの自動化に対する専門労働者の態度:
46.1%のタスクについて、現在それらを実行している労働者は、我々の監査フレームワークでガイドされた雇用喪失や楽しさの減少などの懸念を明示的に考慮した後でも、AIエージェントによる自動化に肯定的な態度を示していることがわかった。

#### 自動化に賛成する回答に対して選択された理由

* 「高価値の仕事のための時間を確保する」 69.38%
* タスクの反復性（46.6%）
* ストレス（25.5%）
* 品質向上の機会（46.6%）が含まれる。

全体的なパターンは、AIエージェントがゼロサムダイナミクスでの代替としてではなく、労働者が低価値または負担の大きいタスクをオフロードできるようにする支援的な役割を果たす可能性があることを示唆している。

#### 労働者はどこでAIエージェントによる自動化に抵抗しているか？(音声回答データを分析)

* 28.0%が「日常業務でのAIの使用をどのように想定していますか？」という質問に答える際に、恐れ、懸念、または否定的な感情を表明した。
   * AIシステムの精度、能力、信頼性に対する信頼の欠如（45.0%）
   * 雇用置換への恐怖（23.0%）
   * AIにおける人間の資質や能力の欠如（16.3%）
      * 仕事における「人間らしさ」の喪失、
      * 創造的なコントロールの減少、
      * 意思決定における主体性の維持への欲求
これらのセクターレベルの内訳では、「芸術、デザイン、メディア」セクターが際立っており、17.1%のタスクのみが肯定的な要望評価を受けている。

### 既存のLLM使用は労働者の要望を反映しているか？

労働者が自動化を最も望んでいる職業は現在、LLM使用において過小代表されている。これは、既存の使用パターンがより広い需要を反映するのではなく、アーリーアダプターや特定の職種に偏っている可能性があることを示唆している

### 職場におけるAIエージェントの要望-能力の景観

* 自動化「青信号」ゾーン：高い自動化要望と高い能力の両方を持つタスク。これらはAIエージェント展開の主要な候補であり、広範な生産性と社会的利益の可能性がある。
* 自動化「赤信号」ゾーン：高い能力だが低い要望を持つタスク。ここでの展開は労働者の抵抗に直面したり、より広い負の社会的影響をもたらす可能性があるため、注意が必要。
* 研究開発機会ゾーン：高い要望だが現在は低い能力を持つタスク。これらはAI研究開発の有望な方向性を表している。
* 低優先度ゾーン：低い要望と低い能力の両方を持つタスク。これらはAIエージェント開発にとってそれほど緊急ではない。

YC企業の41.0%は低優先度ゾーンと自動化「赤信号」ゾーンにマッピングされている一方、「青信号」ゾーンと機会ゾーン内の多くの有望なタスクは現在の投資によって十分に対処されていない。

※YC企業とは、Y Combinator（ワイコンビネーター） というスタートアップアクセラレーターから投資を受けた企業のことです。
　世界でもっとも影響力のあるスタートアップ企業だとのこと

### 3.4 コア人間スキルの潜在的シフト

* 情報処理スキルへの需要の縮小：データ分析と知識更新に関連するスキル—今日の高賃金職業では一般的だが—高い人間主体性を必要とするタスクではそれほど顕著ではない。
* 対人および組織スキルへのより大きな重点：人間のインタラクション、調整、リソース監視を含むスキルは、賃金ベースの評価で現在優先されていなくても、高HASタスクとより頻繁に関連している。
* 高主体性スキルは多様な側面にまたがる：最高の平均必要人間主体性を持つ上位10のスキルは、対人および組織能力から意思決定と品質判断まで、幅広い範囲を包含している。


## メモ本文にタイムスタンプ追加でRAG時の情報衝突をLLMが判断可能に

* https://x.com/super_bonochin/status/2000849159335895119

## シャオミがMiMo-V2-Flash発表、軽量309BパラメータでDeepSeekV3.2と同等性能

* https://x.com/umiyuki_ai/status/2001191737424011639

シャオミのMiMo-V2-FlashがSWEベンチでオープンのモデルではSOTAとのこと。
シャオミでもAI作ってるんですね。

## Gemini 3 Flash、高速・低コストで優れた推論能力とマルチモーダル機能を実現

* https://x.com/omarsar0/status/2001323230779314446

## Gemini 3 Flash、ベンチマーク向上も基本的な質問回答能力は改善されず

* https://x.com/super_bonochin/status/2001419647737065632

実際に使ってみた人の感想と、ベンチの結果が乖離しているようですね
ベンチが強いということは、強い分野もあるはずではあるんですが

## テスト駆動開発はAIへの指示明確化と完璧な仕様書の両方の機能を持つ

* https://x.com/j_kun_ml/status/2001423409968972245

## Gemini 3 Flash、手書き文字認識でGPT-5.2やOpus 4.5を上回る性能

* https://x.com/itnavi2022/status/2001670771689820359

やはり、マルチモーダルでは gemini が強いようですね

## Claude in Chrome、有料プラン全体に提供開始、Claude Code統合も実装

* https://x.com/claudeai/status/2001748044434543082
* https://claude.com/blog/claude-for-chrome

Claude Codeが、Chromeで使えるようになりました。
というか、Claude Code が Chromeを使えるようになったと言う方が正しそうです。
自分のアカウントでインターネットのサイトを触らせるのは怖いですが、
Web系のテストでは、非常に役立ちそうです。

## 【あすけんテックブログ】Claude Code の sub-agent を複数使って過去の意思決定を再検証してみた

* https://tech.asken.inc/entry/20251218

## AnthropicがSkillsとMCPサーバーの使い分けガイドを公開

* https://twitter.com/gota_bara/status/2002256062888681700
* https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers

## Claude Code の LSP（Language Server Protocol）サポート

* https://azukiazusa.dev/blog/claude-code-lsp-support/

コード解析ツールみたいなものと連携して、関数検索とか型情報とかセマンティクスを取得できるようになったらしいですね。
うまく連携したら、かなり賢くなりそう

## Claude for Chromeに音声で画面操作を教える新機能が追加

* https://x.com/sora19ai/status/2002886701073780939

## LLMの間違いをノート記録し参照する手法でファインチューニング並み性能を半額で実現

* https://x.com/ai_database/status/2002922438036976102
* https://ai-data-base.com/archives/99123

## 小規模言語モデルに関する87ページの包括的調査レポートが公開

* https://x.com/omarsar0/status/2003156349736321174

## Anthropic公式のAPI開発からエンタープライズ展開まで学べるアカデミー

* https://www.anthropic.com/learn

充実しすぎていて、どこから見るべきか迷いますね
あとは、動画が英語なのがちょっと敷居高いです

## Claude Codeの4つの機能の違いと使い分けを解説した記事が話題

* ドラゴンを倒して覚える Claude Code - Commands, Skills, Subagents, Rules の違いと使い分け
* https://zenn.dev/yahsan2/articles/claude-code-game-analogy

タイトルに引かれて、つい読んでしまいました 笑
割と分かりやすいと思います。

## OpenAIの新ベンチマークがGemini 3 Proの実務能力不足を暴露

* https://x.com/super_bonochin/status/2000992974818435558

## ChatGPTの画像生成がGPTImage1.5に更新、4倍高速化も品質向上は限定的

* https://x.com/umiyuki_ai/status/2001071792845414743

やはり、画像生成系はGoogleの方が強いとのこと

## 「嘘つきペナルティ」評価でGPTがGemini上回る、情報精度に大差

* https://x.com/K_Ishi_AI/status/1998616633255014584

Geminiの方がGPT5.1より嘘をつきがちという評価結果に
というか、グラウンディング能力でGPTの方が高評価とか不思議ではありますね


## Google、全サービスでMCPサーバ提供開始、マップ等から順次展開

* https://www.itmedia.co.jp/news/articles/2512/12/news077.html

え？ そんなことある？ と思いましたが、フルマネージドのMCPサーバーを提供するとのことですので、
GCPから使えるMCPサーバーを課金して提供っぽいですね。

## Qwen3-Next-80B-A3B-Thinking発表、100万トークン対応でGemini超え

* https://x.com/HuggingPapers/status/1998645065598775547

うーん、中華系LLMが使えない縛りがキツイですね 笑

## プロ声優100名の音声合成APIを法人向けから一般向けに公開開始

* https://x.com/supikiti/status/1998741324242235596

音声生成は色々と権利関係が難しそうなので、こういう風に最初からプロと契約したサービスが正しそうな気がします。

## Google Cloud問題でGemini 3 Proだけ全問不正解、他モデルは全問正解

* https://x.com/super_bonochin/status/1998744034140164393

## Claude Codeサブエージェントと別プロセス起動の使い分けについて

https://x.com/kinopee_ai/status/1998965202948362271

## Codexを使った大規模コードリライトの効率的な進め方

* https://x.com/kenn/status/1999002078354747707

## Google「Gemini 2.5 TTS」が大幅アップデート、無料で高精度な音声合成が可能に

* https://x.com/masahirochaen/status/1999045087335186616

## Claude Codeのフック機能で開発作業を自動化する8種類の解説

* https://x.com/nukonuko/status/1999224138305851656
* https://website.claude.com/blog/how-to-configure-hooks

普通のフックみたいですね。
変なことをするのを、ロジック的に止められたり、絶対やって欲しいことをロジックで実行できるのが良いところでしょうか。
プロンプトで指示しても、うまく聞いてくれないことありますしね。

## GPQA登場から2年でAIスコアが30-40%から93%超に大幅向上

* https://x.com/jaguring1/status/1999271478525886788

## OpenAI、25.6万トークンの長文読解で70%以上の正解率を達成し実用レベルに到達

* https://x.com/K_Ishi_AI/status/1999284325955829843

## AI AgentにClaudeでdraw.io図を描かせる技術記事の紹介

* https://zenn.dev/genda_jp/articles/2025-12-12-drawio-tips-claude-code

## Zoom、AI最高峰ベンチマークで48.1%達成しGoogle超え世界首位

* https://x.com/masahirochaen/status/2000362318333681670

Zoomが「Humanity's Last Exam（HLE）」ベンチマークで48.1%を達成したとのこと。なぜZoomなんでしょうね 笑

* https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough/

## お手伝いロボット「NEO」開発の1X、企業向けに最大1万体展開

* https://japan.cnet.com/article/35241646/

ちょっと欲しいですが、300万円はキツイですね 笑

## AIの台頭でCEOの仕事も脅威に、巨大テック企業が警鐘

* https://jp.wsj.com/articles/ais-next-challenge-take-the-ceos-job-aa13c75d

## ChatGPTの記憶システムはRAGを使っていなかった - 4層アーキテクチャの衝撃

* https://zenn.dev/tenormusica/articles/chatgpt-memory-no-rag-2025

